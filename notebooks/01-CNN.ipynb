{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "987468de-036c-43f8-aef9-acef8fe9f972",
   "metadata": {},
   "source": "# Image classifier"
  },
  {
   "cell_type": "code",
   "id": "b0cc857b-dc54-4078-bd1b-933280a8c0f1",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load the data",
   "id": "bc6ced73a8a9b437"
  },
  {
   "cell_type": "code",
   "id": "0a0823a7-882d-407f-bba6-e6dd01771ba2",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "\n",
    "data_dir = os.path.abspath('../data/raw/train/')\n",
    "\n",
    "# train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#     directory=data_dir,\n",
    "#     labels='inferred',\n",
    "#     seed=42,\n",
    "#     batch_size=32\n",
    "# )\n",
    "\n",
    "# set the images width and height\n",
    "img_width = 224\n",
    "img_height = 224\n",
    "\n",
    "# train dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    image_size=(img_height, img_width),\n",
    "    labels='inferred',\n",
    ")\n",
    "\n",
    "# validation dataset\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=(img_height, img_width),\n",
    "    labels='inferred',\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_ds",
   "id": "2f08b356198ebafe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ],
   "id": "77a7abdef738d478",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Where the labels are:\n",
    "- class_a - cat\n",
    "- class_b - dog"
   ],
   "id": "789d55be03f635ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualize the data",
   "id": "3d65497cfca3a929"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ],
   "id": "2813e25908e39c52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's verify what is the content of train_ds",
   "id": "8f9591cc7316d87e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ],
   "id": "a57a6871996d4763",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The image_batch is a tensor of the shape (32, 256, 256, 3). This is a batch of 32 images of shape 256x256x3 (the last dimension refers to color channels RGB and the images are 256x256 because that is the default value of the **image_dataset_from_directory** function). The label_batch is a tensor of the shape (32,), these are corresponding **labels** to the 32 images.",
   "id": "f4eee178cbcdceff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configure the dataset for performance",
   "id": "b8dcd676dba15357"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We are going to use buffered prefetching, so we can yield data from disk without having I/O become blocking. The two important methods we should use when loading data are:\n",
    "\n",
    "- **Dataset.cache** keeps the images in memory after they're loaded off disk during the first epoch. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.\n",
    "- **Dataset.prefetch** overlaps data preprocessing and model execution while training.\n",
    "Interested readers can learn more about both methods, as well as how to cache data to disk in the Prefetching section of the Better performance with the tf.data API guide."
   ],
   "id": "503edf5bcb44e94a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ],
   "id": "8b14f122b43cec4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Standardize the data",
   "id": "40f85ba7ec2fe7f7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The RGB channel values are in the [0, 255] range. This is not ideal for a neural network; in general you should seek to make your input values small.",
   "id": "a28856f91f629970"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we standardize values to be in the [0, 1] range by using tf.keras.layers.Rescaling:",
   "id": "8d8210c1e2980b80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "normalization_layer = tf.keras.layers.Rescaling(1./255)",
   "id": "a053783c2000047c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now there are two ways to use this layer. We can apply it to the dataset by calling Dataset.map:",
   "id": "48a77c510f91b027"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# normalize all the data\n",
    "normalized_train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "# let's print the first image to see the normalization\n",
    "image_batch, labels_batch = next(iter(normalized_train_ds))\n",
    "first_image = image_batch[0]\n",
    "print('Min and Max values:', np.min(first_image), '-', np.max(first_image))"
   ],
   "id": "ccbb996e756c0448",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Or we can include this layer in the model, the same can be done with the Resizing using the **tf.keras.layers.Resizing** layer.",
   "id": "e0ba48d3e49697a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Now let's create the model (CNN)",
   "id": "40e685ba99566c47"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This time we are following the models given to use:",
   "id": "ac8799c332f0e455"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "    # here is where the rescaling layer can be\n",
    "    # layers.Rescaling(1./255, input_shape=(256, 256, 3)),\n",
    "    layers.Conv2D(input_shape = (224,224,3), filters = 64, kernel_size = (3,3), padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(filters = 64,kernel_size = (3,3),padding = \"same\", activation = \"relu\"),\n",
    "    layers.MaxPool2D(pool_size = (2,2),strides = (2,2)),\n",
    "    layers.Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"),\n",
    "    layers.MaxPool2D(pool_size = (2,2),strides = (2,2)),\n",
    "    layers.Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"),\n",
    "    layers.MaxPool2D(pool_size = (2,2),strides = (2,2)),\n",
    "    layers.Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"),\n",
    "    layers.MaxPool2D(pool_size = (2,2),strides = (2,2)),\n",
    "    layers.Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"),\n",
    "    layers.MaxPool2D(pool_size = (2,2),strides = (2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units = 4096,activation = \"relu\"),\n",
    "    layers.Dense(units = 4096,activation = \"relu\"),\n",
    "    layers.Dense(units = 2, activation = \"softmax\"),\n",
    "])"
   ],
   "id": "6e546e2742271272",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Compile the model",
   "id": "b58402b51e01f869"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This time we are going to use the **tf.keras.optimizers.Adam** optimizer and **tf.keras.losses.SparseCategoricalCrossentropy** loss function.",
   "id": "df7beaf9bd639f77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")"
   ],
   "id": "6b8d29a0e41712e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model summary",
   "id": "28ee893fa3d70d5a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see all the layers of the network using the Keras **Model.summary** method:",
   "id": "539dd67753a9d74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.summary()",
   "id": "4c2e6cfb1c517fbf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train the model",
   "id": "4b823928749ea2b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# epoch to train\n",
    "epochs = 10\n",
    "\n",
    "# train\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ],
   "id": "2820e77c51c296b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b36ccd4e-9749-42b9-ac94-ad1ac6cd5d67",
   "metadata": {},
   "source": [
    "# Predicciones de probabilidad\n",
    "y_proba = model.predict(X_test).flatten()\n",
    "\n",
    "# Cálculo de la métrica AUC\n",
    "auc_score = roc_auc_score(y_test, y_proba)\n",
    "print(f\"AUC Score: {auc_score:.4f}\")\n",
    "\n",
    "# Curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_score:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve: Clasificador Gato vs Perro')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
