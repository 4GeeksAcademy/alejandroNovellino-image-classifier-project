{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "987468de-036c-43f8-aef9-acef8fe9f972",
   "metadata": {},
   "source": "# Image classifier"
  },
  {
   "cell_type": "code",
   "id": "b0cc857b-dc54-4078-bd1b-933280a8c0f1",
   "metadata": {},
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load the data",
   "id": "bc6ced73a8a9b437"
  },
  {
   "cell_type": "code",
   "id": "0a0823a7-882d-407f-bba6-e6dd01771ba2",
   "metadata": {},
   "source": [
    "# get the data from the keras datasets\n",
    "(X_train_full, y_train_full), (X_test_full, y_test_full) = keras.datasets.cifar10.load_data()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| Label | Class          |\n",
    "|-------|----------------|\n",
    "| 0     | airplane ‚úàÔ∏è    |\n",
    "| 1     | automobile üöó  |\n",
    "| 2     | bird üê¶        |\n",
    "| 3     | cat üê±         |\n",
    "| 4     | deer ü¶å        |\n",
    "| 5     | dog üê∂         |\n",
    "| 6     | frog üê∏        |\n",
    "| 7     | horse üê¥       |\n",
    "| 8     | ship üö¢        |\n",
    "| 9     | truck üöö       |\n",
    "\n",
    "We are going to work classifying airplanes and ships."
   ],
   "id": "42de4918fc2c2774"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# filter the data to just stay with the airplanes and the ships\n",
    "y_train = np.where((y_train_full == 0) | (y_train_full == 8))\n",
    "y_test = np.where((y_test_full == 0) | (y_test_full == 8))"
   ],
   "id": "2f08b356198ebafe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# search indexes\n",
    "indices = np.where((y_train == 0) | (y_train == 8))[0]"
   ],
   "id": "414ad18afa09ef47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ],
   "id": "77a7abdef738d478",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualize the data",
   "id": "3d65497cfca3a929"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(tf.keras.backend.get_value(labels[i]))\n",
    "    plt.axis(\"off\")"
   ],
   "id": "2813e25908e39c52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's verify what is the content of train_ds",
   "id": "8f9591cc7316d87e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ],
   "id": "a57a6871996d4763",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The image_batch is a tensor of the shape (12, 120, 120, 3). This is a batch of 16 with shape 160x160x3 (the last dimension refers to color channels RGB and the images are 120x120 because that is the value we set on the **image_dataset_from_directory** function). The label_batch is a tensor of the shape (12,), these are corresponding **labels** to the 12 images.",
   "id": "f4eee178cbcdceff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configure the dataset for performance",
   "id": "b8dcd676dba15357"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We are going to use buffered prefetching, so we can yield data from disk without having I/O become blocking. The two important methods we should use when loading data are:\n",
    "\n",
    "- **Dataset.cache** keeps the images in memory after they're loaded off disk during the first epoch. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.\n",
    "- **Dataset.prefetch** overlaps data preprocessing and model execution while training.\n",
    "Interested readers can learn more about both methods."
   ],
   "id": "503edf5bcb44e94a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ],
   "id": "8b14f122b43cec4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Standardize the data",
   "id": "40f85ba7ec2fe7f7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The RGB channel values are in the [0, 255] range. This is not ideal for a neural network; in general you should seek to make your input values small.",
   "id": "a28856f91f629970"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we standardize values to be in the [0, 1] range by using tf.keras.layers.Rescaling:",
   "id": "8d8210c1e2980b80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# normalization_layer = tf.keras.layers.Rescaling(1./255)",
   "id": "a053783c2000047c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now there are two ways to use this layer. We can apply it to the dataset by calling Dataset.map:",
   "id": "48a77c510f91b027"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# normalize all the data\n",
    "# normalized_train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "# let's print the first image to see the normalization\n",
    "# image_batch, labels_batch = next(iter(normalized_train_ds))\n",
    "# first_image = image_batch[0]\n",
    "# print('Min and Max values:', np.min(first_image), '-', np.max(first_image))"
   ],
   "id": "ccbb996e756c0448",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Or we can include this layer in the model, the same can be done with the Resizing using the **tf.keras.layers.Resizing** layer (we are going to do this option).",
   "id": "e0ba48d3e49697a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Now let's create the model (CNN)",
   "id": "40e685ba99566c47"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This time we are following the models given to use:",
   "id": "ac8799c332f0e455"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from keras import Sequential, layers, regularizers\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    # set this Input layer to delete the warning\n",
    "    layers.Input(shape=(img_height, img_width, 3)),\n",
    "    # here is where the rescaling layer can be\n",
    "    layers.Rescaling(1./255),\n",
    "\n",
    "    # rest of the layers\n",
    "    layers.Conv2D(filters = 32, kernel_size = (3,3), padding = \"same\", activation = \"relu\", kernel_regularizer=regularizers.L2(0.001)),\n",
    "    layers.Conv2D(filters = 32,kernel_size = (3,3),padding = \"same\", activation = \"relu\", kernel_regularizer=regularizers.L2(0.001)),\n",
    "    layers.MaxPool2D(pool_size = (2,2),strides = (2,2)),\n",
    "    # dropout layer\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Conv2D(filters = 64, kernel_size = (3,3), padding = \"same\", activation = \"relu\", kernel_regularizer=regularizers.L2(0.001)),\n",
    "    layers.Conv2D(filters = 64, kernel_size = (3,3), padding = \"same\", activation = \"relu\", kernel_regularizer=regularizers.L2(0.001)),\n",
    "    layers.MaxPool2D(pool_size = (2,2),strides = (2,2)),\n",
    "    # dropout layer\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units = 512,activation = \"relu\", kernel_regularizer=regularizers.L2(0.001)),\n",
    "    # dropout layer\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(units = 512,activation = \"relu\", kernel_regularizer=regularizers.L2(0.001)),\n",
    "    # dropout layer\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    # output layer\n",
    "    layers.Dense(units = 2, activation = \"softmax\"),\n",
    "])"
   ],
   "id": "6e546e2742271272",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Compile the model",
   "id": "b58402b51e01f869"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This time we are going to use the **tf.keras.optimizers.Adam** optimizer and **tf.keras.losses.SparseCategoricalCrossentropy** loss function.",
   "id": "df7beaf9bd639f77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=['categorical_crossentropy'], # use this loss function based on the load labels that we used\n",
    "    metrics=['accuracy'] # we can use accuracy because the training data is balanced\n",
    ")"
   ],
   "id": "6b8d29a0e41712e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model summary",
   "id": "28ee893fa3d70d5a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see all the layers of the network using the Keras **Model.summary** method:",
   "id": "539dd67753a9d74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.summary()",
   "id": "4c2e6cfb1c517fbf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train the model",
   "id": "4b823928749ea2b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# filter warnings to not see them during training (this is not working)\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ],
   "id": "18018ca00690584a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Early stopping conf",
   "id": "eacee18021371fe3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from keras.src.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',         # metric to verify\n",
    "    patience=25,                 # number of epochs without change to stop\n",
    "    restore_best_weights=True\n",
    ")"
   ],
   "id": "b2cca01003e7d64d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Learning rate scheduler",
   "id": "474a1e5956828eef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from keras.src.callbacks import LearningRateScheduler\n",
    "\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    \"\"\"\n",
    "    Scheduler that reduces the learning rate by 10.\n",
    "    \"\"\"\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * 0.1\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)"
   ],
   "id": "e37377c2085a4080",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Fitting of the model",
   "id": "b41ecd1d06635f81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# epoch to train\n",
    "epochs = 100\n",
    "\n",
    "# train\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=0\n",
    ")"
   ],
   "id": "2820e77c51c296b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualize training results",
   "id": "292b845b9c453dd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get the values to graph\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(history.history['val_accuracy']))\n",
    "\n",
    "# create the graphs\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ],
   "id": "20a13815da6dbb31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Analysis",
   "id": "804c4905cf7d688c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save the model",
   "id": "3c1eab06ce98ffd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "save_dir = os.path.abspath('/mnt/f/Courses/4GeeksAcademy/DataScience/DeliverableExercises/alejandroNovellino-image-classifier-project/models')\n",
    "\n",
    "model.save(f'{save_dir}/in_data_simpler_base_model.keras')"
   ],
   "id": "a8895f2daad73140",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now clear the memory to continue working",
   "id": "1e8fe6b1b1835ec9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from keras.src.backend.common.global_state import clear_session\n",
    "\n",
    "clear_session(\n",
    "    free_memory=True\n",
    ")"
   ],
   "id": "3dc71c20cd4cd157",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
