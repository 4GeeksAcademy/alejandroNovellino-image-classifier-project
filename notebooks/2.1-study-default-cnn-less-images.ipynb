{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import tensorflow as tf",
   "id": "68dbd7b9f8ecc3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load the data",
   "id": "bc6ced73a8a9b437"
  },
  {
   "cell_type": "code",
   "id": "0a0823a7-882d-407f-bba6-e6dd01771ba2",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "\n",
    "data_dir = os.path.abspath('/mnt/f/Courses/4GeeksAcademy/DataScience/DeliverableExercises/alejandroNovellino-image-classifier-project/data/raw/test_2')\n",
    "\n",
    "# set the image width and height\n",
    "img_width = 160\n",
    "img_height = 160\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# train dataset\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    seed=42,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical'\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_ds",
   "id": "414ad18afa09ef47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class_names = test_ds.class_names\n",
    "print(class_names)"
   ],
   "id": "77a7abdef738d478",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We have two labels the **cat** and **dog** labels.",
   "id": "789d55be03f635ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configure the dataset for performance",
   "id": "b8dcd676dba15357"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We are going to use buffered prefetching, so we can yield data from disk without having I/O become blocking. The two important methods we should use when loading data are:\n",
    "\n",
    "- **Dataset.cache** keeps the images in memory after they're loaded off disk during the first epoch. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.\n",
    "- **Dataset.prefetch** overlaps data preprocessing and model execution while training.\n",
    "Interested readers can learn more about both methods, as well as how to cache data to disk in the Prefetching section of the Better performance with the tf.data API guide."
   ],
   "id": "503edf5bcb44e94a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_ds = test_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)",
   "id": "8b14f122b43cec4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The model itself does the normalization, so no work on the data must be done.",
   "id": "a28856f91f629970"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Now let's load the model",
   "id": "40e685ba99566c47"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import keras\n",
    "\n",
    "model_dir = os.path.abspath('/mnt/f/Courses/4GeeksAcademy/DataScience/DeliverableExercises/alejandroNovellino-image-classifier-project/models/model_2.keras')\n",
    "\n",
    "model = keras.saving.load_model(model_dir)"
   ],
   "id": "6e546e2742271272",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Analyze the results",
   "id": "9a6cf622024ab112"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# make the prediction\n",
    "y_pred = model.predict(test_ds, verbose=0)"
   ],
   "id": "fefb0e81b681e299",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_pred",
   "id": "567eb6b12398d370",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a dataframe with the predictions\n",
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "y_pred_df['predicted_class'] = y_pred_df.idxmax(axis=1)\n",
    "y_pred_df['predicted_proba'] = y_pred_df[[0, 1]].max(axis=1)"
   ],
   "id": "c3cba73dadca04ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_pred_df",
   "id": "f32bca5a1cdcbf2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Metrics",
   "id": "7d326dcf102cc2c3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can calculate the accuracy of the CNN with the model.evaluate method. Or/and we can see the results wht sckit",
   "id": "316864dcc827ea32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "_, accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ],
   "id": "7b11184d73c6b2d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Clear the memory",
   "id": "66a6c800ab65ce71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "keras.backend.clear_session()",
   "id": "3dc71c20cd4cd157",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
